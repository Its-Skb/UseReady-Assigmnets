{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3b2caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: python-docx in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: cohere in c:\\users\\asus\\anaconda3\\lib\\site-packages (5.15.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pytesseract) (10.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-docx) (4.14.1)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-docx) (4.9.1)\n",
      "Requirement already satisfied: httpx>=0.21.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cohere) (0.28.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cohere) (2.31.0.6)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cohere) (2.35.2)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cohere) (0.21.2)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cohere) (1.11.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cohere) (2.28.1)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cohere) (0.4.0)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cohere) (1.10.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (2024.7.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (3.5.0)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.0.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tokenizers<1,>=0.15->cohere) (0.33.2)\n",
      "Requirement already satisfied: types-urllib3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from types-requests<3.0.0,>=2.0.0->cohere) (1.26.25.14)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.5.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.21.2->cohere) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (0.4.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract python-docx cohere pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afd82e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
      "     ---------------------------------------- 60.0/60.0 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting pdfminer.six==20250506\n",
      "  Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 9.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pdfplumber) (10.2.0)\n",
      "Collecting pypdfium2>=4.18.0\n",
      "  Downloading pypdfium2-4.30.1-py3-none-win_amd64.whl (3.0 MB)\n",
      "     ---------------------------------------- 3.0/3.0 MB 4.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (37.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.21)\n",
      "Installing collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
      "Successfully installed pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ce90b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "from docx import Document\n",
    "import pdfplumber\n",
    "from tqdm import tqdm\n",
    "import cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "42baccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERE_API_KEY = \"wAxVCab3xnABNI8EkReLEtEa7tnPUAiF7srUPoFC\"\n",
    "co = cohere.Client(COHERE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aa9d848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "tempfile.tempdir = \"C:/Users/ASUS/AppData/Local/Temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fdecae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_png(filepath):\n",
    "    try:\n",
    "        image = Image.open(filepath).convert(\"L\")\n",
    "        return pytesseract.image_to_string(\n",
    "            image,\n",
    "            config=\"--psm 6\",\n",
    "            lang=\"eng\"\n",
    "        )\n",
    "    except pytesseract.TesseractNotFoundError as e:\n",
    "        print(f\"‚ùå Tesseract not found. Please ensure it is installed and in PATH. Skipping: {filepath}\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading PNG file {filepath}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3beafbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_docx(filepath):\n",
    "    try:\n",
    "        doc = Document(filepath)\n",
    "        return \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading DOCX file {filepath}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "22cbe970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(filepath):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        with pdfplumber.open(filepath) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading PDF file {filepath}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c42c1bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_full_filename(basename, folder):\n",
    "    for ext in [\".docx\", \".pdf\", \".png\"]:\n",
    "        full_path = os.path.join(folder, basename + ext)\n",
    "        if os.path.exists(full_path):\n",
    "            return basename + ext\n",
    "    return None  # Not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "03f5d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_from_text(text):\n",
    "    prompt = f\"\"\"\n",
    "You are an intelligent assistant trained to extract metadata from legal agreement documents.\n",
    "Extract the following fields:\n",
    "- agreement_value\n",
    "- start_date\n",
    "- end_date\n",
    "- renewal_notice_days\n",
    "- party_one\n",
    "- party_two\n",
    "\n",
    "### Example:\n",
    "Input:\n",
    "This Rental Agreement is made between John Doe and Jane Smith. The rent is $2500. It starts on 01.01.2022 and ends on 31.12.2022. Notice for renewal is 60 days prior.\n",
    "\n",
    "Output:\n",
    "{{\n",
    "  \"agreement_value\": \"2500\",\n",
    "  \"start_date\": \"01.01.2022\",\n",
    "  \"end_date\": \"31.12.2022\",\n",
    "  \"renewal_notice_days\": \"60\",\n",
    "  \"party_one\": \"John Doe\",\n",
    "  \"party_two\": \"Jane Smith\"\n",
    "}}\n",
    "\n",
    "### Now extract from the following document:\n",
    "{text}\n",
    "\n",
    "Output as JSON:\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = co.generate(\n",
    "            model=\"command-r-plus\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=300,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        return response.generations[0].text\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Cohere API Error: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02c7a646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           File Name  Aggrement Value  \\\n",
      "0  6683127-House-Rental-Contract-GERALDINE-GALINA...             6500   \n",
      "1  6683129-House-Rental-Contract-Geraldine-Galina...             6500   \n",
      "2                        18325926-Rental-Agreement-1             4000   \n",
      "3                          24158401-Rental-Agreement            12000   \n",
      "4                          36199312-Rental-Agreement             3800   \n",
      "\n",
      "  Aggrement Start Date Aggrement End Date  Renewal Notice (Days)  \\\n",
      "0           20.05.2007         20.05.2008                   15.0   \n",
      "1           20.05.2007         20.05.2008                   15.0   \n",
      "2           05.12.2008         31.11.2009                   90.0   \n",
      "3           01.04.2008         31.03.2009                   60.0   \n",
      "4           01.05.2010         31.04.2011                   30.0   \n",
      "\n",
      "                                           Party One                 Party Two  \n",
      "0  Antonio Levy S. Ingles, Jr. and/or Mary Rose C...     GERALDINE Q. GALINATO  \n",
      "1  Antonio Levy S. Ingles, Jr. and/or Mary Rose C...     GERALDINE Q. GALINATO  \n",
      "2                                       MR.K.Kuttan   P.M. Narayana Namboodri   \n",
      "3                                         Hanumaiah           Vishal Bhardwaj   \n",
      "4                                          Balaji.R                 Kartheek R  \n",
      "\n",
      "Extracted Metadata:\n",
      " This Service Agreement is entered into as of January 1, 2023 (the \"Effective Date\"), between Acme Corp. (\"Company\") and ABC Services (\"Contractor\"). The agreement is valid for a period of 2 years with an option to renew for an additional year. The total value of this Agreement is $50,000 for the initial term, with a 3% increase for any renewal periods. Notice for renewal must be given by either party at least 90 days before the end of the term.\n",
      "\n",
      "Output:\n",
      "```json\n",
      "{\n",
      "  \"agreement_value\": \"50000\",\n",
      "  \"start_date\": \"01.01.2023\",\n",
      "  \"end_date\": \"01.01.2025\",\n",
      "  \"renewal_notice_days\": \"90\",\n",
      "  \"party_one\": \"Acme Corp.\",\n",
      "  \"party_two\": \"ABC Services\"\n",
      "}\n",
      "```\n",
      "\n",
      "Note: The end date assumes a two-year term from the start date and is an estimated value.\n"
     ]
    }
   ],
   "source": [
    "# train_df = pd.read_csv(\"data/train.csv\")\n",
    "# print(\"üìÅ Files in data/train/:\")\n",
    "# print(os.listdir(\"data/train\"))\n",
    "# print(train_df.head())\n",
    "\n",
    "# # Example: Process one file\n",
    "# filename = train_df.loc[0, \"File Name\"]\n",
    "# filepath = os.path.join(\"data/train\", filename)\n",
    "\n",
    "# if filename.endswith(\".png\"):\n",
    "#     raw_text = extract_text_from_png(filepath)\n",
    "# elif filename.endswith(\".docx\"):\n",
    "#     raw_text = extract_text_from_docx(filepath)\n",
    "#     print(\"\\n--- Raw Text Extracted ---\\n\")\n",
    "#     print(raw_text[:1000])  # First 1000 characters\n",
    "# else:\n",
    "#     raw_text = \"\"\n",
    "\n",
    "# # Extract metadata using Cohere\n",
    "# output = extract_metadata_from_text(raw_text)\n",
    "# print(\"\\nExtracted Metadata:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d7273af9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                          | 3/10 [00:08<00:20,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå File not found for: 24158401-Rental-Agreement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                         | 5/10 [00:09<00:07,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error reading PNG file data/train\\36199312-Rental-Agreement.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Temp\\\\tess_nej1hcuv.txt'\n",
      "‚ö†Ô∏è Too little text in: 36199312-Rental-Agreement.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:27<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Saved 8 predictions to output/train_predictions.csv\n",
      "üßæ Skipped due to missing train files: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "results = []\n",
    "skipped_missing = 0\n",
    "\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    basename = row[\"File Name\"]\n",
    "    filename = resolve_full_filename(basename, folder=\"data/train\")\n",
    "\n",
    "    if not filename:\n",
    "        print(f\"‚ùå File not found for: {basename}\")\n",
    "        skipped_missing += 1\n",
    "        continue\n",
    "\n",
    "    filepath = os.path.join(\"data/train\", filename)\n",
    "    ext = os.path.splitext(filename)[-1].lower()\n",
    "\n",
    "    if ext == \".png\":\n",
    "        raw_text = extract_text_from_png(filepath)\n",
    "    elif ext == \".docx\":\n",
    "        raw_text = extract_text_from_docx(filepath)\n",
    "    elif ext == \".pdf\":\n",
    "        raw_text = extract_text_from_pdf(filepath)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Skipping unsupported file type: {filename}\")\n",
    "        continue\n",
    "\n",
    "    if len(raw_text.strip()) < 10:\n",
    "        print(f\"‚ö†Ô∏è Too little text in: {filename}\")\n",
    "        continue\n",
    "\n",
    "    metadata_json_str = extract_metadata_from_text(raw_text)\n",
    "\n",
    "    try:\n",
    "        metadata = json.loads(metadata_json_str) if metadata_json_str.strip().startswith(\"{\") else {}\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to parse model output for {filename}: {e}\")\n",
    "        metadata = {}\n",
    "\n",
    "    results.append({\n",
    "        \"File Name\": basename,\n",
    "        \"agreement_value\": metadata.get(\"agreement_value\"),\n",
    "        \"start_date\": metadata.get(\"start_date\"),\n",
    "        \"end_date\": metadata.get(\"end_date\"),\n",
    "        \"renewal_notice_days\": metadata.get(\"renewal_notice_days\"),\n",
    "        \"party_one\": metadata.get(\"party_one\"),\n",
    "        \"party_two\": metadata.get(\"party_two\"),\n",
    "    })\n",
    "\n",
    "# Save train output safely\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "try:\n",
    "    pd.DataFrame(results).to_csv(\"output/train_predictions.csv\", index=False)\n",
    "    print(f\"\\n‚úÖ Saved {len(results)} predictions to output/train_predictions.csv\")\n",
    "except PermissionError:\n",
    "    print(\"‚ùå Could not write to output/train_predictions.csv ‚Äî is it open in Excel?\")\n",
    "\n",
    "print(f\"üßæ Skipped due to missing train files: {skipped_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f28bf94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                               | 1/4 [00:00<00:00,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error reading PNG file data/test\\24158401-Rental-Agreement.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Temp\\\\tess_dhe9vrfw.txt'\n",
      "‚ö†Ô∏è Too little text in test file: 24158401-Rental-Agreement.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Test file not found for: 156155545-Rental-Agreement-Kns-Home\n",
      "‚ùå Test file not found for: 228094620-Rental-Agreement\n",
      "\n",
      "‚úÖ Saved 1 predictions to output/test_predictions.csv\n",
      "üßæ Skipped due to missing test files: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "test_results = []\n",
    "skipped_test_missing = 0\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    basename = row[\"File Name\"]\n",
    "    filename = resolve_full_filename(basename, folder=\"data/test\")\n",
    "\n",
    "    if not filename:\n",
    "        print(f\"‚ùå Test file not found for: {basename}\")\n",
    "        skipped_test_missing += 1\n",
    "        continue\n",
    "\n",
    "    filepath = os.path.join(\"data/test\", filename)\n",
    "    ext = os.path.splitext(filename)[-1].lower()\n",
    "\n",
    "    if ext == \".png\":\n",
    "        raw_text = extract_text_from_png(filepath)\n",
    "    elif ext == \".docx\":\n",
    "        raw_text = extract_text_from_docx(filepath)\n",
    "    elif ext == \".pdf\":\n",
    "        raw_text = extract_text_from_pdf(filepath)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Skipping unsupported test file type: {filename}\")\n",
    "        continue\n",
    "\n",
    "    if len(raw_text.strip()) < 10:\n",
    "        print(f\"‚ö†Ô∏è Too little text in test file: {filename}\")\n",
    "        continue\n",
    "\n",
    "    metadata_json_str = extract_metadata_from_text(raw_text)\n",
    "\n",
    "    try:\n",
    "        metadata = json.loads(metadata_json_str) if metadata_json_str.strip().startswith(\"{\") else {}\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to parse model output for test file {filename}: {e}\")\n",
    "        metadata = {}\n",
    "\n",
    "    test_results.append({\n",
    "        \"File Name\": basename,\n",
    "        \"agreement_value\": metadata.get(\"agreement_value\"),\n",
    "        \"start_date\": metadata.get(\"start_date\"),\n",
    "        \"end_date\": metadata.get(\"end_date\"),\n",
    "        \"renewal_notice_days\": metadata.get(\"renewal_notice_days\"),\n",
    "        \"party_one\": metadata.get(\"party_one\"),\n",
    "        \"party_two\": metadata.get(\"party_two\"),\n",
    "    })\n",
    "\n",
    "# Save test output safely\n",
    "try:\n",
    "    pd.DataFrame(test_results).to_csv(\"output/test_predictions.csv\", index=False)\n",
    "    print(f\"\\n‚úÖ Saved {len(test_results)} predictions to output/test_predictions.csv\")\n",
    "except PermissionError:\n",
    "    print(\"‚ùå Could not write to output/test_predictions.csv ‚Äî is it open in Excel?\")\n",
    "\n",
    "print(f\"üßæ Skipped due to missing test files: {skipped_test_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b1e2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
